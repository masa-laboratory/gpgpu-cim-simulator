//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-28358933
// Cuda compilation tools, release 11.0, V11.0.167
// Based on LLVM 3.4svn
//

.version 7.0
.target sm_75
.address_size 64

	// .globl	_Z19mma16816NaiveKernelPK6__halfS1_PS_mmm
// _ZZ19mma16816NaiveKernelPK6__halfS1_PS_mmmE7shmem_A has been demoted
// _ZZ19mma16816NaiveKernelPK6__halfS1_PS_mmmE7shmem_B has been demoted
// _ZZ19mma16816NaiveKernelPK6__halfS1_PS_mmmE7shmem_C has been demoted

.visible .entry _Z19mma16816NaiveKernelPK6__halfS1_PS_mmm(
	.param .u64 _Z19mma16816NaiveKernelPK6__halfS1_PS_mmm_param_0,
	.param .u64 _Z19mma16816NaiveKernelPK6__halfS1_PS_mmm_param_1,
	.param .u64 _Z19mma16816NaiveKernelPK6__halfS1_PS_mmm_param_2,
	.param .u64 _Z19mma16816NaiveKernelPK6__halfS1_PS_mmm_param_3,
	.param .u64 _Z19mma16816NaiveKernelPK6__halfS1_PS_mmm_param_4,
	.param .u64 _Z19mma16816NaiveKernelPK6__halfS1_PS_mmm_param_5
)
{
	.reg .pred 	%p<18>;
	.reg .b32 	%r<236>;
	.reg .b64 	%rd<133>;
	// demoted variable
	.shared .align 2 .b8 _ZZ19mma16816NaiveKernelPK6__halfS1_PS_mmmE7shmem_A[512];
	// demoted variable
	.shared .align 2 .b8 _ZZ19mma16816NaiveKernelPK6__halfS1_PS_mmmE7shmem_B[256];
	// demoted variable
	.shared .align 2 .b8 _ZZ19mma16816NaiveKernelPK6__halfS1_PS_mmmE7shmem_C[256];

	ld.param.u64 	%rd18, [_Z19mma16816NaiveKernelPK6__halfS1_PS_mmm_param_0];
	ld.param.u64 	%rd19, [_Z19mma16816NaiveKernelPK6__halfS1_PS_mmm_param_1];
	ld.param.u64 	%rd20, [_Z19mma16816NaiveKernelPK6__halfS1_PS_mmm_param_2];
	ld.param.u64 	%rd23, [_Z19mma16816NaiveKernelPK6__halfS1_PS_mmm_param_3];
	ld.param.u64 	%rd21, [_Z19mma16816NaiveKernelPK6__halfS1_PS_mmm_param_4];
	ld.param.u64 	%rd22, [_Z19mma16816NaiveKernelPK6__halfS1_PS_mmm_param_5];
	.loc 1 30 26
	mov.u32 	%r5, %ctaid.x;
	shl.b32 	%r6, %r5, 4;
	cvt.u64.u32	%rd24, %r6;
	.loc 1 31 26
	mov.u32 	%r7, %ctaid.y;
	shl.b32 	%r8, %r7, 3;
	cvt.u64.u32	%rd25, %r8;
	.loc 1 33 5
	setp.ge.u64	%p4, %rd25, %rd21;
	setp.ge.u64	%p5, %rd24, %rd23;
	or.pred  	%p6, %p4, %p5;
	@%p6 bra 	BB0_28;

	.loc 1 43 25
	mov.u32 	%r1, %tid.x;
	.loc 1 27 26
	add.s64 	%rd26, %rd22, 15;
	shr.u64 	%rd27, %rd26, 4;
	.loc 1 49 5
	setp.eq.s64	%p7, %rd27, 0;
	@%p7 bra 	BB0_25;

	.loc 1 50 9
	bfe.u32 	%r9, %r1, 1, 4;
	shl.b32 	%r10, %r9, 5;
	mov.u32 	%r11, _ZZ19mma16816NaiveKernelPK6__halfS1_PS_mmmE7shmem_A;
	add.s32 	%r12, %r11, %r10;
	and.b32  	%r14, %r1, 1;
	shl.b32 	%r15, %r14, 4;
	add.s32 	%r2, %r12, %r15;
	cvt.u64.u32	%rd32, %r9;
	.loc 1 54 13
	mov.u32 	%r16, _ZZ19mma16816NaiveKernelPK6__halfS1_PS_mmmE7shmem_B;
	add.s32 	%r17, %r16, %r10;
	add.s32 	%r3, %r17, %r15;
	add.s64 	%rd34, %rd32, %rd25;
	mul.lo.s64 	%rd1, %rd34, %rd22;
	bfe.u64 	%rd31, %rd26, 4, 2;
	mov.u64 	%rd127, 0;
	setp.eq.s64	%p8, %rd31, 0;
	@%p8 bra 	BB0_14;

	setp.eq.s64	%p9, %rd31, 1;
	@%p9 bra 	BB0_11;

	setp.eq.s64	%p10, %rd31, 2;
	@%p10 bra 	BB0_8;

	.loc 1 43 25
	and.b32  	%r21, %r1, 31;
	.loc 1 50 9
	bfe.u32 	%r22, %r1, 1, 4;
	or.b32  	%r25, %r22, %r6;
	cvt.u64.u32	%rd36, %r25;
	mul.lo.s64 	%rd37, %rd36, %rd22;
	.loc 1 27 26
	cvta.to.global.u64 	%rd38, %rd18;
	.loc 1 50 9
	shl.b64 	%rd39, %rd37, 1;
	add.s64 	%rd40, %rd38, %rd39;
	mul.wide.u32 	%rd41, %r14, 16;
	add.s64 	%rd42, %rd40, %rd41;
	ld.global.nc.v4.u32 	{%r27, %r28, %r29, %r30}, [%rd42];
	st.shared.v4.u32 	[%r2], {%r27, %r28, %r29, %r30};
	.loc 1 53 9
	setp.gt.u32	%p11, %r21, 15;
	@%p11 bra 	BB0_7;

	.loc 1 27 26
	cvta.to.global.u64 	%rd43, %rd19;
	.loc 1 54 13
	shl.b64 	%rd44, %rd1, 1;
	add.s64 	%rd45, %rd43, %rd44;
	add.s64 	%rd47, %rd45, %rd41;
	ld.global.nc.v4.u32 	{%r37, %r38, %r39, %r40}, [%rd47];
	st.shared.v4.u32 	[%r3], {%r37, %r38, %r39, %r40};

BB0_7:
	.loc 1 58 9
	bar.sync 	0;
	.loc 1 83 9
	mov.u32 	%r45, _ZZ19mma16816NaiveKernelPK6__halfS1_PS_mmmE7shmem_C;
	{
	.reg .u64 %temp; 
	cvt.u64.u32 	%temp, %r45;
	cvta.shared.u64 	%rd48, %temp;
	}
	{
	.reg .u64 %temp; 
	cvt.u64.u32 	%temp, %r11;
	cvta.shared.u64 	%rd49, %temp;
	}
	{
	.reg .u64 %temp; 
	cvt.u64.u32 	%temp, %r16;
	cvta.shared.u64 	%rd50, %temp;
	}
	// inline asm
	cimma.shmma.synchro.rowmajor.colmajor.m16n8k16.f16.f16 [%rd48], [%rd49], [%rd50];
	// inline asm
	.loc 1 85 9
	bar.sync 	0;
	mov.u64 	%rd127, 1;

BB0_8:
	.loc 1 43 25
	and.b32  	%r49, %r1, 31;
	.loc 1 50 9
	bfe.u32 	%r50, %r1, 1, 4;
	or.b32  	%r53, %r50, %r6;
	cvt.u64.u32	%rd52, %r53;
	mul.lo.s64 	%rd53, %rd52, %rd22;
	shl.b64 	%rd54, %rd127, 4;
	add.s64 	%rd55, %rd54, %rd53;
	.loc 1 27 26
	cvta.to.global.u64 	%rd56, %rd18;
	.loc 1 50 9
	shl.b64 	%rd57, %rd55, 1;
	add.s64 	%rd58, %rd56, %rd57;
	mul.wide.u32 	%rd59, %r14, 16;
	add.s64 	%rd60, %rd58, %rd59;
	ld.global.nc.v4.u32 	{%r55, %r56, %r57, %r58}, [%rd60];
	st.shared.v4.u32 	[%r2], {%r55, %r56, %r57, %r58};
	.loc 1 53 9
	setp.gt.u32	%p12, %r49, 15;
	@%p12 bra 	BB0_10;

	.loc 1 54 13
	add.s64 	%rd62, %rd54, %rd1;
	.loc 1 27 26
	cvta.to.global.u64 	%rd63, %rd19;
	.loc 1 54 13
	shl.b64 	%rd64, %rd62, 1;
	add.s64 	%rd65, %rd63, %rd64;
	add.s64 	%rd67, %rd65, %rd59;
	ld.global.nc.v4.u32 	{%r65, %r66, %r67, %r68}, [%rd67];
	st.shared.v4.u32 	[%r3], {%r65, %r66, %r67, %r68};

BB0_10:
	.loc 1 58 9
	bar.sync 	0;
	.loc 1 83 9
	mov.u32 	%r73, _ZZ19mma16816NaiveKernelPK6__halfS1_PS_mmmE7shmem_C;
	{
	.reg .u64 %temp; 
	cvt.u64.u32 	%temp, %r73;
	cvta.shared.u64 	%rd68, %temp;
	}
	{
	.reg .u64 %temp; 
	cvt.u64.u32 	%temp, %r11;
	cvta.shared.u64 	%rd69, %temp;
	}
	{
	.reg .u64 %temp; 
	cvt.u64.u32 	%temp, %r16;
	cvta.shared.u64 	%rd70, %temp;
	}
	// inline asm
	cimma.shmma.synchro.rowmajor.colmajor.m16n8k16.f16.f16 [%rd68], [%rd69], [%rd70];
	// inline asm
	.loc 1 85 9
	bar.sync 	0;
	.loc 1 49 37
	add.s64 	%rd127, %rd127, 1;

BB0_11:
	.loc 1 43 25
	and.b32  	%r77, %r1, 31;
	.loc 1 50 9
	bfe.u32 	%r78, %r1, 1, 4;
	or.b32  	%r81, %r78, %r6;
	cvt.u64.u32	%rd71, %r81;
	mul.lo.s64 	%rd72, %rd71, %rd22;
	shl.b64 	%rd5, %rd127, 4;
	add.s64 	%rd73, %rd5, %rd72;
	.loc 1 27 26
	cvta.to.global.u64 	%rd74, %rd18;
	.loc 1 50 9
	shl.b64 	%rd75, %rd73, 1;
	add.s64 	%rd76, %rd74, %rd75;
	mul.wide.u32 	%rd77, %r14, 16;
	add.s64 	%rd78, %rd76, %rd77;
	ld.global.nc.v4.u32 	{%r83, %r84, %r85, %r86}, [%rd78];
	st.shared.v4.u32 	[%r2], {%r83, %r84, %r85, %r86};
	.loc 1 53 9
	setp.gt.u32	%p13, %r77, 15;
	@%p13 bra 	BB0_13;

	.loc 1 54 13
	add.s64 	%rd79, %rd5, %rd1;
	.loc 1 27 26
	cvta.to.global.u64 	%rd80, %rd19;
	.loc 1 54 13
	shl.b64 	%rd81, %rd79, 1;
	add.s64 	%rd82, %rd80, %rd81;
	add.s64 	%rd84, %rd82, %rd77;
	ld.global.nc.v4.u32 	{%r93, %r94, %r95, %r96}, [%rd84];
	st.shared.v4.u32 	[%r3], {%r93, %r94, %r95, %r96};

BB0_13:
	.loc 1 58 9
	bar.sync 	0;
	.loc 1 83 9
	mov.u32 	%r101, _ZZ19mma16816NaiveKernelPK6__halfS1_PS_mmmE7shmem_C;
	{
	.reg .u64 %temp; 
	cvt.u64.u32 	%temp, %r101;
	cvta.shared.u64 	%rd85, %temp;
	}
	{
	.reg .u64 %temp; 
	cvt.u64.u32 	%temp, %r11;
	cvta.shared.u64 	%rd86, %temp;
	}
	{
	.reg .u64 %temp; 
	cvt.u64.u32 	%temp, %r16;
	cvta.shared.u64 	%rd87, %temp;
	}
	// inline asm
	cimma.shmma.synchro.rowmajor.colmajor.m16n8k16.f16.f16 [%rd85], [%rd86], [%rd87];
	// inline asm
	.loc 1 85 9
	bar.sync 	0;
	.loc 1 49 37
	add.s64 	%rd127, %rd127, 1;

BB0_14:
	.loc 1 27 26
	setp.lt.u64	%p14, %rd26, 64;
	@%p14 bra 	BB0_25;

	.loc 1 50 9
	bfe.u32 	%r105, %r1, 1, 4;
	or.b32  	%r108, %r105, %r6;
	cvt.u64.u32	%rd89, %r105;
	.loc 1 50 9
	cvt.u64.u32	%rd90, %r108;
	mul.lo.s64 	%rd91, %rd22, %rd90;
	shl.b64 	%rd92, %rd127, 4;
	add.s64 	%rd93, %rd91, %rd92;
	mul.wide.u32 	%rd94, %r14, 8;
	add.s64 	%rd95, %rd93, %rd94;
	.loc 1 27 26
	cvta.to.global.u64 	%rd96, %rd18;
	.loc 1 50 9
	shl.b64 	%rd97, %rd95, 1;
	add.s64 	%rd131, %rd96, %rd97;
	add.s64 	%rd99, %rd89, %rd25;
	mul.lo.s64 	%rd100, %rd22, %rd99;
	add.s64 	%rd101, %rd100, %rd92;
	add.s64 	%rd102, %rd101, %rd94;
	.loc 1 27 26
	cvta.to.global.u64 	%rd103, %rd19;
	.loc 1 50 9
	shl.b64 	%rd104, %rd102, 1;
	add.s64 	%rd132, %rd103, %rd104;
	.loc 1 43 25
	and.b32  	%r4, %r1, 31;

BB0_16:
	.loc 1 50 9
	ld.global.nc.v4.u32 	{%r112, %r113, %r114, %r115}, [%rd131];
	st.shared.v4.u32 	[%r2], {%r112, %r113, %r114, %r115};
	.loc 1 53 9
	setp.gt.u32	%p15, %r4, 15;
	@%p15 bra 	BB0_18;

	.loc 1 54 13
	ld.global.nc.v4.u32 	{%r120, %r121, %r122, %r123}, [%rd132];
	shl.b32 	%r129, %r1, 4;
	.loc 1 50 9
	and.b32  	%r130, %r129, 480;
	.loc 1 54 13
	add.s32 	%r132, %r16, %r130;
	and.b32  	%r133, %r129, 16;
	add.s32 	%r134, %r132, %r133;
	st.shared.v4.u32 	[%r134], {%r120, %r121, %r122, %r123};

BB0_18:
	setp.lt.u32	%p1, %r4, 16;
	.loc 1 58 9
	bar.sync 	0;
	.loc 1 83 9
	mov.u32 	%r135, _ZZ19mma16816NaiveKernelPK6__halfS1_PS_mmmE7shmem_C;
	{
	.reg .u64 %temp; 
	cvt.u64.u32 	%temp, %r135;
	cvta.shared.u64 	%rd106, %temp;
	}
	{
	.reg .u64 %temp; 
	cvt.u64.u32 	%temp, %r11;
	cvta.shared.u64 	%rd107, %temp;
	}
	{
	.reg .u64 %temp; 
	cvt.u64.u32 	%temp, %r16;
	cvta.shared.u64 	%rd108, %temp;
	}
	// inline asm
	cimma.shmma.synchro.rowmajor.colmajor.m16n8k16.f16.f16 [%rd106], [%rd107], [%rd108];
	// inline asm
	.loc 1 85 9
	bar.sync 	0;
	.loc 1 50 9
	ld.global.nc.v4.u32 	{%r138, %r139, %r140, %r141}, [%rd131+32];
	st.shared.v4.u32 	[%r2], {%r138, %r139, %r140, %r141};
	.loc 1 53 9
	@!%p1 bra 	BB0_20;
	bra.uni 	BB0_19;

BB0_19:
	.loc 1 54 13
	ld.global.nc.v4.u32 	{%r146, %r147, %r148, %r149}, [%rd132+32];
	shl.b32 	%r155, %r1, 4;
	.loc 1 50 9
	and.b32  	%r156, %r155, 480;
	.loc 1 54 13
	add.s32 	%r158, %r16, %r156;
	and.b32  	%r159, %r155, 16;
	add.s32 	%r160, %r158, %r159;
	st.shared.v4.u32 	[%r160], {%r146, %r147, %r148, %r149};

BB0_20:
	.loc 1 58 9
	bar.sync 	0;
	.loc 1 83 9
	// inline asm
	cimma.shmma.synchro.rowmajor.colmajor.m16n8k16.f16.f16 [%rd106], [%rd107], [%rd108];
	// inline asm
	.loc 1 85 9
	bar.sync 	0;
	.loc 1 50 9
	ld.global.nc.v4.u32 	{%r164, %r165, %r166, %r167}, [%rd131+64];
	st.shared.v4.u32 	[%r2], {%r164, %r165, %r166, %r167};
	.loc 1 53 9
	@!%p1 bra 	BB0_22;
	bra.uni 	BB0_21;

BB0_21:
	.loc 1 54 13
	ld.global.nc.v4.u32 	{%r172, %r173, %r174, %r175}, [%rd132+64];
	shl.b32 	%r181, %r1, 4;
	.loc 1 50 9
	and.b32  	%r182, %r181, 480;
	.loc 1 54 13
	add.s32 	%r184, %r16, %r182;
	and.b32  	%r185, %r181, 16;
	add.s32 	%r186, %r184, %r185;
	st.shared.v4.u32 	[%r186], {%r172, %r173, %r174, %r175};

BB0_22:
	.loc 1 58 9
	bar.sync 	0;
	.loc 1 83 9
	// inline asm
	cimma.shmma.synchro.rowmajor.colmajor.m16n8k16.f16.f16 [%rd106], [%rd107], [%rd108];
	// inline asm
	.loc 1 85 9
	bar.sync 	0;
	.loc 1 50 9
	ld.global.nc.v4.u32 	{%r190, %r191, %r192, %r193}, [%rd131+96];
	st.shared.v4.u32 	[%r2], {%r190, %r191, %r192, %r193};
	.loc 1 53 9
	@!%p1 bra 	BB0_24;
	bra.uni 	BB0_23;

BB0_23:
	.loc 1 54 13
	ld.global.nc.v4.u32 	{%r198, %r199, %r200, %r201}, [%rd132+96];
	shl.b32 	%r207, %r1, 4;
	.loc 1 50 9
	and.b32  	%r208, %r207, 480;
	.loc 1 54 13
	add.s32 	%r210, %r16, %r208;
	and.b32  	%r211, %r207, 16;
	add.s32 	%r212, %r210, %r211;
	st.shared.v4.u32 	[%r212], {%r198, %r199, %r200, %r201};

BB0_24:
	.loc 1 58 9
	bar.sync 	0;
	.loc 1 83 9
	// inline asm
	cimma.shmma.synchro.rowmajor.colmajor.m16n8k16.f16.f16 [%rd106], [%rd107], [%rd108];
	// inline asm
	.loc 1 85 9
	bar.sync 	0;
	.loc 1 49 37
	add.s64 	%rd127, %rd127, 4;
	.loc 1 49 5
	setp.lt.u64	%p16, %rd127, %rd27;
	add.s64 	%rd131, %rd131, 128;
	add.s64 	%rd132, %rd132, 128;
	.loc 1 49 5
	@%p16 bra 	BB0_16;

BB0_25:
	.loc 1 43 25
	and.b32  	%r217, %r1, 31;
	.loc 1 88 5
	setp.gt.u32	%p17, %r217, 15;
	@%p17 bra 	BB0_27;

	.loc 1 43 25
	cvt.u64.u32	%rd118, %r217;
	.loc 1 89 9
	add.s64 	%rd120, %rd118, %rd24;
	mul.lo.s64 	%rd121, %rd120, %rd21;
	add.s64 	%rd123, %rd121, %rd25;
	.loc 1 27 26
	cvta.to.global.u64 	%rd124, %rd20;
	.loc 1 89 9
	shl.b64 	%rd125, %rd123, 1;
	add.s64 	%rd126, %rd124, %rd125;
	shl.b32 	%r224, %r1, 4;
	and.b32  	%r225, %r224, 496;
	mov.u32 	%r226, _ZZ19mma16816NaiveKernelPK6__halfS1_PS_mmmE7shmem_C;
	add.s32 	%r227, %r226, %r225;
	ld.shared.v4.u32 	{%r228, %r229, %r230, %r231}, [%r227];
	st.global.v4.u32 	[%rd126], {%r228, %r229, %r230, %r231};

BB0_27:
	.loc 1 92 5
	bar.sync 	0;

BB0_28:
	.loc 1 93 1
	ret;
}

	.file	1 "/home/yangjianchao/Github/gpgpu-cim-simulator/cuda_codes/simple_cim_codes/cimma.cu", 1685702571, 15460
	.file	2 "/usr/local/cuda/include/cuda_device_runtime_api.h", 1680603975, 14970
	.file	3 "/usr/local/cuda/include/cuda_fp16.hpp", 1680603975, 81204
	.file	4 "/usr/local/cuda/include/cuda_runtime.h", 1680603975, 88951

